{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHvH4XhYjua2"
      },
      "source": [
        "# Imports & Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "o7wxG0T2h1CC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVSDY1b0j5hJ"
      },
      "source": [
        "## Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHQj7nMHj4f7",
        "outputId": "52677112-a2f1-4ecf-bd7b-e46f08b0eb52"
      },
      "outputs": [],
      "source": [
        "%pip install transformers evaluate langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ-2bZdLj-Wc"
      },
      "source": [
        "## Upload files to collab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ooh0_9-vj8Ik",
        "outputId": "1ad40e10-2367-4458-b10b-0e44012a95b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files, drive\n",
        "drive.mount('/content/drive/')\n",
        "# data = files.upload()\n",
        "data = pd.read_json('/content/drive/My Drive/dataset.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXdkfi20pkPV"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "DR1jeHgSpmMW",
        "outputId": "064082a0-97ca-431f-a9e0-bb8605c8046b"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1QFxF4Dp6Wy",
        "outputId": "48d52c61-904a-44a4-fefb-e4f2ddddbcab"
      },
      "outputs": [],
      "source": [
        "print(data.describe())\n",
        "print(data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tbJlVTfQqJfL"
      },
      "outputs": [],
      "source": [
        "def preprocessing(df):\n",
        "  df['review_text'] = df['review_text'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "5MjF_YMUqje1",
        "outputId": "63ab6231-a101-40e7-b701-142b88c40638"
      },
      "outputs": [],
      "source": [
        "preprocessing(data)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2G3se0Yi-H5"
      },
      "source": [
        "## Zero-shot Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkRJusWdkCPy"
      },
      "outputs": [],
      "source": [
        "#from langchain_huggingface.llms import HuggingFacePipeline\n",
        "\n",
        "from transformers import AlbertForSequenceClassification, AlbertTokenizer, pipeline\n",
        "\n",
        "model_id = \"albert-base-v2\"\n",
        "tokenizer = AlbertTokenizer.from_pretrained(model_id)\n",
        "model = AlbertForSequenceClassification.from_pretrained(model_id, num_labels=5)\n",
        "\n",
        "\n",
        "pipe = pipeline(\"zero-shot-classification\", model=model_id)\n",
        "\n",
        "candidate_labels =[\"Good\", \"Bad\"]\n",
        "\n",
        "#print(data['review_text'][17])\n",
        "\n",
        "output = pipe(data['review_text'][17], candidate_labels)\n",
        "output1 = pipe(data['review_text'][18], candidate_labels)\n",
        "output2 = pipe(data['review_text'][19], candidate_labels)\n",
        "\n",
        "\n",
        "print(output)\n",
        "print(output1)\n",
        "print(output2)\n",
        "\n",
        "\n",
        "prompt = \"Your objective is to read user reviews for books and determine the final rating given by the user on a scale of 1 to 5 stars. Being 1 the lowest score and 5 the highest.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uqc38SEaqKY_"
      },
      "source": [
        "## Few-Shot Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvxqJIU3jDQu",
        "outputId": "20cb70ba-324d-4442-e644-abaea743bde5"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import AlbertForSequenceClassification, AlbertTokenizer, pipeline\n",
        "\n",
        "model_id = \"facebook/bart-large-mnli\"\n",
        "pipe = pipeline(\"zero-shot-classification\", model=model_id)\n",
        "\n",
        "candidate_labels =[\"0 Stars\", \"1 Stars\", \"2 Stars\", \"3 Stars\", \"4 Stars\", \"5 Stars\"]\n",
        "\n",
        "examples_text = [\n",
        "    data['review_text'][17],\n",
        "    data['review_text'][18],\n",
        "    data['review_text'][19],\n",
        "  ]\n",
        "\n",
        "examples_ratings = [\n",
        "    data['rating'][17],\n",
        "    data['rating'][18],\n",
        "    data['rating'][19],\n",
        "]\n",
        "\n",
        "query = data['review_text'][10]\n",
        "label = data['rating'][10]\n",
        "\n",
        "prompt = \"\"\"Your objective is to read user reviews for books and determine the final rating given by the user on a scale of 1 to 5 stars. Being 0 the lowest score and 5 the highest. First you'll get 3 examples of\n",
        "Text: {review text}\n",
        "Rating: {rating on a scale of 0 to 5}\n",
        "\n",
        "Examples:\n",
        "\"\"\"\n",
        "\n",
        "fo = prompt + \"\\n Text:\" + examples_text[0] + \"\\n Rating:\" + str(examples_ratings[0]) + \"\\n\" + \" Text:\" + examples_text[1] + \"\\n Rating:\" + str(examples_ratings[1]) + \"\\n\" + \" Text:\" + examples_text[2] + \"\\n Rating:\" + str(examples_ratings[2]) + \"\\n\" + \" Text:\" + query\n",
        "\n",
        "\n",
        "\n",
        "output2 = pipe(fo, candidate_labels)\n",
        "\n",
        "\n",
        "print(output2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "fHADq3UVjrn-",
        "outputId": "37212738-80d3-4246-be1d-9018f4cdba84"
      },
      "outputs": [],
      "source": [
        "print(query)\n",
        "print(label)\n",
        "data.iloc[10:11]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
